{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization\n",
    "Hyperparameters dictate the parameters of the training process and the architecture of the model itself. For example, the \n",
    "number of random trees is a hyperparameter for a **random forest**. In contrast, a learned parameter for a **random forest** is the set of features that is contained in a single node (in a single tree) and the cutoff values for each of those features that determines how the data is split at that node. A full discussion of hyperparameter optimization can be found on **[Wikipedia](https://en.wikipedia.org/wiki/Hyperparameter_optimization)**.\n",
    "\n",
    "The choice of hyperparameters strongly influences model performance,\n",
    "so it is important to be able to optimize them as well. **[AMPL](https://github.com/ATOMScience-org/AMPL)**\n",
    "offers a variety of hyperparameter optimization methods including\n",
    "random sampling, grid search, and Bayesian optimization. Please refer to the parameter documentation \n",
    "**[page](https://github.com/ATOMScience-org/AMPL#hyperparameter-optimization)** for further information.\n",
    "\n",
    "In this tutorial we demonstrate the following:\n",
    "- Build a parameter dictionary to perform a hyperparameter search for a **random forest** using Bayesian optimization.\n",
    "- Perform the optimization process.\n",
    "- Review the results\n",
    "\n",
    "We will use these **[AMPL](https://github.com/ATOMScience-org/AMPL)** functions:\n",
    "- [parse_params](https://ampl.readthedocs.io/en/latest/utils.html#utils.hyperparam_search_wrapper.parse_params)\n",
    "- [build_search](https://ampl.readthedocs.io/en/latest/utils.html#utils.hyperparam_search_wrapper.build_search)\n",
    "- [run_search](https://ampl.readthedocs.io/en/latest/utils.html#utils.hyperparam_search_wrapper.HyperOptSearch.run_search)\n",
    "- [get_filesystem_perf_results](https://ampl.readthedocs.io/en/latest/pipeline.html#pipeline.compare_models.get_filesystem_perf_results)\n",
    "\n",
    "The first three functions in the above list come from the `hyperparameter_search_wrapper` module. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Directories\n",
    "\n",
    "Here we set up a few important variables corresponding to required directories and specific features for the **hyperparameter optimization (HPO)** process. Then, we ensure that the directories are created before saving models into them.\n",
    "\n",
    "|Variable|Description|\n",
    "|---|---|\n",
    "|`dataset_key`|The relative path to the dataset you want to use for HPO|\n",
    "|`descriptor_type`|The type of features you want to use during HPO|\n",
    "|`model_dir`|The directory where you want to save all of the models|\n",
    "|`best_model_dir`|For Bayesian optimization, the winning model is saved in this separate folder|\n",
    "|`split_uuid`|The presaved split uuid from **Tutorial 2, \"Splitting Datasets for Validation and Testing\"**|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "import os\n",
    "\n",
    "meas='MMP'\n",
    "dataset_key='../datasets_ST/MMP/scaled_descriptors/MMPcleanC.csv'\n",
    "featurizer = 'computed_descriptors' #computed_descriptors, ecfp, chemberta\n",
    "descriptor_type = 'rdkit_raw' #mordred_filtered, rdkit_raw, moe\n",
    "\n",
    "split_uuid = '8507d7de-0beb-4c8b-9f3b-26f7d34293d3'\n",
    "\n",
    "# ST models for ROS only\n",
    "model_dir = f'{meas}_models'\n",
    "best_model_dir = f'{meas}_models/best_models'\n",
    "\n",
    "\n",
    "# for meas in ['CellCount','MitoStruct','ROS','GSH','NucMask','NucArea','MMP','MT']:\n",
    "#     if meas!=\"MT\":\n",
    "#         model_dir = f'ST_models/{meas}_models'\n",
    "#         best_model_dir = f'ST_models/{meas}_models/best_models'\n",
    "#     else:\n",
    "#         model_dir = f'{meas}_models'\n",
    "#         best_model_dir = f'{meas}_models/best_models'\n",
    "\n",
    "#     if not os.path.exists(f'./{model_dir}'):\n",
    "#         os.makedirs(f'./{model_dir}')\n",
    "\n",
    "#     if not os.path.exists(f'./{best_model_dir}'):\n",
    "#         os.makedirs(f'./{best_model_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a hyperparameter search, we first create a parameter dictionary with parameter settings that will be common to all models, along with some special parameters that control the search and indicate which parameters will be varied and how. The table below describes the special parameter settings for our random forest search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Dictionary Settings\n",
    "\n",
    "|Parameter|Description|\n",
    "|---|---|\n",
    "|`'hyperparam':'True'`|This setting indicates that we are performing a hyperparameter search instead of just training one model.|\n",
    "|`'previously_featurized':'True'`|This tells **[AMPL](https://github.com/ATOMScience-org/AMPL)** to search for previously generated features in `../dataset/scaled_descriptors` instead of regenerating them on the fly.|\n",
    "|`'search_type':'hyperopt'`|This specifies the hyperparameter search method. Other options include `grid`, `random`, and `geometric`. Specifications for each hyperparameter search method is different, please refer to the full documentation. Here we are using the Bayesian optimization method.|\n",
    "|`'model_type':'RF\\|10'`|This means **[AMPL](https://github.com/ATOMScience-org/AMPL)** will try 10 times to find the best set of hyperparameters using **random forests**. In practice, this parameter could be set to 100 or more.|\n",
    "|`'rfe':'uniformint\\|8,512'`|The Bayesian optimizer will uniformly search between 8 and 512 for the best number of random forest estimators. Similarly `rfd` stands for **random forest depth** and `rff` stands for **random forest features**.|\n",
    "|`result_dir`|Now expects two parameters. The first directory will contain the best trained models while the second directory will contain all models trained in the search.|\n",
    "\n",
    "Regression models are optimized to maximize the $R^2$ and\n",
    "classification models are optimized using area under the \n",
    "receiver operating characteristic curve.\n",
    "A full list of parameters can be found on our\n",
    "**[github](https://github.com/ATOMScience-org/AMPL/blob/master/atomsci/ddm/docs/PARAMETERS.md)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    \"hyperparam\": \"True\",\n",
    "    \"prediction_type\": \"classification\",\n",
    "\n",
    "    \"dataset_key\": dataset_key,\n",
    "    \"id_col\": \"compound_id\",\n",
    "    \"smiles_col\": \"base_rdkit_smiles\",\n",
    "    \"response_cols\": f\"active\",\n",
    "\n",
    "    \"splitter\":\"scaffold\",\n",
    "    \"split_uuid\": split_uuid,\n",
    "    \"previously_split\": \"True\",\n",
    "\n",
    "    \"featurizer\": \"computed_descriptors\", #\"ecfp\", computed_descriptors\n",
    "    \"descriptor_type\" : \"chemberta\", #\"rdkit_raw\", # \"mordred_filtered\", \"chemberta\"\n",
    "    \"transformers\": \"True\",\n",
    "    \"previously_featurized\": \"True\",\n",
    "\n",
    "    \"search_type\": \"hyperopt\",\n",
    "    \"model_type\": \"RF|100\",\n",
    "    \"rfe\": \"uniformint|8,512\",\n",
    "    \"rfd\": \"uniformint|6,32\",\n",
    "    \"rff\": \"uniformint|8,200\",\n",
    "\n",
    "    \"weight_transform_type\": \"balancing\",\n",
    "\n",
    "    \"result_dir\": f\"./{best_model_dir},./{model_dir}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Hyperparameter Search\n",
    "In **Tutorial 3, \"Train a Simple Regression Model\"**, we directly imported the `parameter_parser` and `model_pipeline` objects to parse the `config` dict and train a single model. Here, we use `hyperparameter_search_wrapper` to handle many models for us. First we build the search by creating a list of parameters to use, and then we run the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import atomsci.ddm.utils.hyperparam_search_wrapper as hsw\n",
    "import importlib\n",
    "importlib.reload(hsw)\n",
    "# ampl_param = hsw.parse_params(params)\n",
    "# hs = hsw.build_search(ampl_param)\n",
    "# hs.run_search()\n",
    "\n",
    "for params in [\n",
    "    # rf_params,\n",
    "    xg_params,\n",
    "    # nn_params,\n",
    "    ]:\n",
    "    for meas in [\n",
    "        # 'CellCount',\n",
    "        # 'MitoStruct',\n",
    "        # 'ROS',\n",
    "        # 'GSH',\n",
    "        # 'NucMask',\n",
    "        # 'NucArea',\n",
    "        'MMP'\n",
    "        # 'MT'\n",
    "        ]:\n",
    "        params['response_cols'] = \"active\"\n",
    "        # response_col = 'active_MMP,active_CellCount,active_MitoStruct,active_ROS,active_GSH,active_NucMask,active_NucArea'\n",
    "        # params['response_cols'] = response_col\n",
    "        params[\"result_dir\"]=f\"./MMP_models/{meas}_models/best_models,./MMP_models/{meas}_models\"\n",
    "        ampl_param = hsw.parse_params(params)\n",
    "        hs = hsw.build_search(ampl_param)\n",
    "        hs.run_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top scoring model will be saved in `dataset/SLC6A3_models/best_models` along with a csv file\n",
    "containing regression performance for all trained models.\n",
    "\n",
    "All of the models are saved in `dataset/SLC6A3_models`. These models can be\n",
    "explored using `get_filesystem_perf_results`. A full analysis of the hyperparameter performance is explored in **Tutorial 6, \"Compare models to select the best hyperparameters\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found data for 1200 models under ./MMP_models/MMP_models\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_uuid</th>\n",
       "      <th>model_parameters_dict</th>\n",
       "      <th>best_valid_roc_auc_score</th>\n",
       "      <th>best_test_roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>df43ff88-122f-4aa7-90ac-099d7ea384b8</td>\n",
       "      <td>{\"xgb_alpha\": 0.0, \"xgb_colsample_bytree\": 0.2...</td>\n",
       "      <td>0.827599</td>\n",
       "      <td>0.793240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>825c7499-ce8e-449c-ad70-7c574bb423c5</td>\n",
       "      <td>{\"xgb_alpha\": 0.0, \"xgb_colsample_bytree\": 0.2...</td>\n",
       "      <td>0.826542</td>\n",
       "      <td>0.787777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>842d1574-de1e-4bed-87a5-71de53d8fc4c</td>\n",
       "      <td>{\"xgb_alpha\": 0.0, \"xgb_colsample_bytree\": 0.2...</td>\n",
       "      <td>0.824555</td>\n",
       "      <td>0.798731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>bd4f8b9c-ed20-4992-8cc2-e8109ae86568</td>\n",
       "      <td>{\"best_epoch\": 5, \"dropouts\": [0.2879202600111...</td>\n",
       "      <td>0.824104</td>\n",
       "      <td>0.780208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>0f13a630-d9cc-4854-bb63-9b67dc35a105</td>\n",
       "      <td>{\"best_epoch\": 11, \"dropouts\": [0.300519051527...</td>\n",
       "      <td>0.822366</td>\n",
       "      <td>0.800524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model_uuid  \\\n",
       "790  df43ff88-122f-4aa7-90ac-099d7ea384b8   \n",
       "785  825c7499-ce8e-449c-ad70-7c574bb423c5   \n",
       "712  842d1574-de1e-4bed-87a5-71de53d8fc4c   \n",
       "34   bd4f8b9c-ed20-4992-8cc2-e8109ae86568   \n",
       "942  0f13a630-d9cc-4854-bb63-9b67dc35a105   \n",
       "\n",
       "                                 model_parameters_dict  \\\n",
       "790  {\"xgb_alpha\": 0.0, \"xgb_colsample_bytree\": 0.2...   \n",
       "785  {\"xgb_alpha\": 0.0, \"xgb_colsample_bytree\": 0.2...   \n",
       "712  {\"xgb_alpha\": 0.0, \"xgb_colsample_bytree\": 0.2...   \n",
       "34   {\"best_epoch\": 5, \"dropouts\": [0.2879202600111...   \n",
       "942  {\"best_epoch\": 11, \"dropouts\": [0.300519051527...   \n",
       "\n",
       "     best_valid_roc_auc_score  best_test_roc_auc_score  \n",
       "790                  0.827599                 0.793240  \n",
       "785                  0.826542                 0.787777  \n",
       "712                  0.824555                 0.798731  \n",
       "34                   0.824104                 0.780208  \n",
       "942                  0.822366                 0.800524  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import atomsci.ddm.pipeline.compare_models as cm\n",
    "\n",
    "model_dir = f'./MMP_models/MMP_models'\n",
    "\n",
    "result_df = cm.get_filesystem_perf_results(\n",
    "    result_dir = model_dir,\n",
    "    pred_type='classification'\n",
    ")\n",
    "\n",
    "# sort by validation r2 score to see top performing models\n",
    "result_df = result_df.sort_values(by='best_valid_roc_auc_score', ascending=False)\n",
    "result_df[['model_uuid','model_parameters_dict','best_valid_roc_auc_score','best_test_roc_auc_score']].head()\n",
    "\n",
    "# import pandas as pd\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# result_df[['model_uuid','model_parameters_dict']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atomsci.ddm.pipeline import compare_models as cm\n",
    "from atomsci.ddm.pipeline import hyper_perf_plots as hpp\n",
    "from atomsci.ddm.pipeline import perf_plots as pp\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# ignore warnings in tutorials\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 70)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_uuid</th>\n",
       "      <th>split_uuid</th>\n",
       "      <th>best_train_roc_auc_score</th>\n",
       "      <th>best_valid_roc_auc_score</th>\n",
       "      <th>best_test_roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>df43ff88-122f-4aa7-90ac-099d7ea384b8</td>\n",
       "      <td>8507d7de-0beb-4c8b-9f3b-26f7d34293d3</td>\n",
       "      <td>0.967104</td>\n",
       "      <td>0.827599</td>\n",
       "      <td>0.793240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>825c7499-ce8e-449c-ad70-7c574bb423c5</td>\n",
       "      <td>8507d7de-0beb-4c8b-9f3b-26f7d34293d3</td>\n",
       "      <td>0.961752</td>\n",
       "      <td>0.826542</td>\n",
       "      <td>0.787777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>842d1574-de1e-4bed-87a5-71de53d8fc4c</td>\n",
       "      <td>8507d7de-0beb-4c8b-9f3b-26f7d34293d3</td>\n",
       "      <td>0.968441</td>\n",
       "      <td>0.824555</td>\n",
       "      <td>0.798731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>bd4f8b9c-ed20-4992-8cc2-e8109ae86568</td>\n",
       "      <td>8507d7de-0beb-4c8b-9f3b-26f7d34293d3</td>\n",
       "      <td>0.944135</td>\n",
       "      <td>0.824104</td>\n",
       "      <td>0.780208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>0f13a630-d9cc-4854-bb63-9b67dc35a105</td>\n",
       "      <td>8507d7de-0beb-4c8b-9f3b-26f7d34293d3</td>\n",
       "      <td>0.918607</td>\n",
       "      <td>0.822366</td>\n",
       "      <td>0.800524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model_uuid  \\\n",
       "790  df43ff88-122f-4aa7-90ac-099d7ea384b8   \n",
       "785  825c7499-ce8e-449c-ad70-7c574bb423c5   \n",
       "712  842d1574-de1e-4bed-87a5-71de53d8fc4c   \n",
       "34   bd4f8b9c-ed20-4992-8cc2-e8109ae86568   \n",
       "942  0f13a630-d9cc-4854-bb63-9b67dc35a105   \n",
       "\n",
       "                               split_uuid  best_train_roc_auc_score  \\\n",
       "790  8507d7de-0beb-4c8b-9f3b-26f7d34293d3                  0.967104   \n",
       "785  8507d7de-0beb-4c8b-9f3b-26f7d34293d3                  0.961752   \n",
       "712  8507d7de-0beb-4c8b-9f3b-26f7d34293d3                  0.968441   \n",
       "34   8507d7de-0beb-4c8b-9f3b-26f7d34293d3                  0.944135   \n",
       "942  8507d7de-0beb-4c8b-9f3b-26f7d34293d3                  0.918607   \n",
       "\n",
       "     best_valid_roc_auc_score  best_test_roc_auc_score  \n",
       "790                  0.827599                 0.793240  \n",
       "785                  0.826542                 0.787777  \n",
       "712                  0.824555                 0.798731  \n",
       "34                   0.824104                 0.780208  \n",
       "942                  0.822366                 0.800524  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df=result_df.sort_values('best_valid_roc_auc_score', ascending=False)\n",
    "print(result_df.shape)\n",
    "\n",
    "# show useful columns \n",
    "result_df[['model_uuid', 'split_uuid', 'best_train_roc_auc_score', 'best_valid_roc_auc_score', 'best_test_roc_auc_score']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpp.plot_train_valid_test_scores(result_df, prediction_type='classification')\n",
    "\n",
    "hpp.plot_hyper_perf(result_df, model_type='RF', subset='valid', scoretype='roc_auc_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of Other Parameter Sets\n",
    "Below are some parameters that can be used for **neural networks**, \n",
    "**[XGBoost](https://en.wikipedia.org/wiki/XGBoost)** models, \n",
    "**fingerprint splits** and **[ECFP](https://pubs.acs.org/doi/10.1021/ci100050t)** features.\n",
    "Each set of parameters can be used to replace the parameters above. \n",
    "Trying them out is left as an exercise for the reader.\n",
    "\n",
    "#### Neural Network Hyperopt Search\n",
    "\n",
    "|Parameter|Description|\n",
    "|---|---|\n",
    "|`lr`| This controls the learning rate. loguniform\\|-13.8,-3 means the logarithm of the learning rate is uniformly distributed between -13.8 and -3.|\n",
    "|`ls` |This controls layer sizes. 3\\|8,512 means 3 layers with sizes ranging between 8 and 512 neurons. A good strategy is to start with a fewer layers and slowly increase the number until performance plateaus.| \n",
    "|`dp`| This controls dropout. 3\\|0,0.4 means 3 dropout layers with probability of zeroing a weight between 0 and 40%. This needs to match the number of layers specified with `ls` and should range between 0% and 50%. |\n",
    "|`max_epochs`| This controls how long to train each model. Training for more epochs increases runtime, but allows models more time to optimize. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_params = {\n",
    "    \"hyperparam\": \"True\",\n",
    "    \"prediction_type\": \"classification\",\n",
    "\n",
    "    \"dataset_key\": dataset_key,\n",
    "    \"id_col\": \"compound_id\",\n",
    "    \"smiles_col\": \"base_rdkit_smiles\",\n",
    "    # \"response_cols\": \"avg_pKi\",\n",
    "\n",
    "    \"splitter\": \"scaffold\",\n",
    "    \"split_uuid\": split_uuid,\n",
    "    \"previously_split\": \"True\",\n",
    "\n",
    "    \"featurizer\": \"computed_descriptors\", #ecfp, computed_descriptors\n",
    "    \"descriptor_type\" : \"chemberta\", #rdkit_raw\", # \"mordred_filtered\", \"chemberta\"\n",
    "    \"transformers\": \"True\",\n",
    "    \"previously_featurized\": \"True\",\n",
    "\n",
    "    ### Use a NN model\n",
    "    \"search_type\": \"hyperopt\",\n",
    "    \"model_type\": \"NN|100\",\n",
    "    \"lr\": \"loguniform|-13.8,-3\", # e^-13.8 to e^-3\n",
    "    \"ls\": \"uniformint|3|8,512\",\n",
    "    \"dp\": \"uniform|3|0,0.4\",\n",
    "    \"max_epochs\":100,\n",
    "    ###\n",
    "    \"weight_transform_type\": \"balancing\",\n",
    "    # \"class_number\":3,\n",
    "    # \"result_dir\": f\"./{best_model_dir},./{model_dir}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "- `xgbg` Stands for `xgb_gamma` and controls the minimum loss \n",
    "reduction required to make a further partition on a leaf node of the tree.\n",
    "- `xgbl` Stands for `xgb_learning_rate` and controls the boosting \n",
    "learning rate searching domain of  **[XGBoost](https://en.wikipedia.org/wiki/XGBoost)** models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_params = {\n",
    "    \"hyperparam\": \"True\",\n",
    "    \"prediction_type\": \"classification\",\n",
    "\n",
    "    \"dataset_key\": dataset_key,\n",
    "    \"id_col\": \"compound_id\",\n",
    "    \"smiles_col\": \"base_rdkit_smiles\",\n",
    "    # \"response_cols\": \"avg_pKi\",\n",
    "\n",
    "    \"splitter\":\"scaffold\",\n",
    "    \"split_uuid\": split_uuid,\n",
    "    \"previously_split\": \"True\",\n",
    "\n",
    "    \"featurizer\": \"computed_descriptors\", #computed_descriptors\n",
    "    \"descriptor_type\" : \"chemberta\", #rdkit_raw\", # \"mordred_filtered\", \"chemberta\"\n",
    "    \"transformers\": \"True\",\n",
    "    \"previously_featurized\": \"True\",\n",
    "\n",
    "\n",
    "    ### Use an XGBoost model\n",
    "    \"search_type\": \"hyperopt\",\n",
    "    \"model_type\": \"xgboost|100\",\n",
    "    \"xgbg\": \"uniform|0,0.2\", # gamma\n",
    "    \"xgbn\": \"uniformint|8,512\", # num_estimators\n",
    "    \"xgbd\": \"uniformint|2,8\", # max_depth\n",
    "    \"xgbw\": \"uniform|0.1,3\", # min_child_weight\n",
    "    \"xgbl\": \"loguniform|-5,0\", # learning rate\n",
    "    \"xgbc\": \"uniform|0.2,1.0\", # colsample_bytree\n",
    "    \"xgbs\": \"uniform|0.2,1.0\", # subsample\n",
    "    ###\n",
    "\n",
    "    \"weight_transform_type\": \"balancing\",\n",
    "    # \"result_dir\": f\"./{best_model_dir},./{model_dir}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fingerprint Split\n",
    "This trains an  **[XGBoost](https://en.wikipedia.org/wiki/XGBoost)** model using a\n",
    "**fingerprint split**. The fingerprint split is provided with the dataset files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_split_uuid=\"be60c264-6ac0-4841-a6b6-41bf846e4ae4\"\n",
    "\n",
    "fp_params = {\n",
    "    \"hyperparam\": \"True\",\n",
    "    \"prediction_type\": \"regression\",\n",
    "\n",
    "    \"dataset_key\": dataset_key,\n",
    "    \"id_col\": \"compound_id\",\n",
    "    \"smiles_col\": \"base_rdkit_smiles\",\n",
    "    \"response_cols\": \"avg_pKi\",\n",
    "\n",
    "    ### Use a fingerprint split\n",
    "    \"splitter\":\"fingerprint\",\n",
    "    \"split_uuid\": fp_split_uuid,\n",
    "    \"previously_split\": \"True\",\n",
    "    ###\n",
    "\n",
    "    \"featurizer\": \"computed_descriptors\",\n",
    "    \"descriptor_type\" : descriptor_type,\n",
    "    \"transformers\": \"True\",\n",
    "\n",
    "    \"search_type\": \"hyperopt\",\n",
    "    \"model_type\": \"xgboost|10\",\n",
    "    \"xgbg\": \"uniform|0,0.2\",\n",
    "    \"xgbl\": \"loguniform|-2,2\",\n",
    "\n",
    "    \"result_dir\": f\"./{best_model_dir},./{model_dir}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ECFP Features\n",
    "This uses an  **[XGBoost](https://en.wikipedia.org/wiki/XGBoost)** model with **[ECFP fingerprints](https://pubs.acs.org/doi/10.1021/ci100050t)** features and a **scaffold split**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_params = {\n",
    "    \"hyperparam\": \"True\",\n",
    "    \"prediction_type\": \"regression\",\n",
    "\n",
    "    \"dataset_key\": dataset_key,\n",
    "    \"id_col\": \"compound_id\",\n",
    "    \"smiles_col\": \"base_rdkit_smiles\",\n",
    "    \"response_cols\": \"avg_pKi\",\n",
    "\n",
    "    \"splitter\":\"scaffold\",\n",
    "    \"split_uuid\": split_uuid,\n",
    "    \"previously_split\": \"True\",\n",
    "\n",
    "    ### Use ECFP Features\n",
    "    \"featurizer\": \"ecfp\",\n",
    "    \"ecfp_radius\" : 2,\n",
    "    \"ecfp_size\" : 1024,\n",
    "    \"transformers\": \"True\",\n",
    "    ###\n",
    "\n",
    "    \"search_type\": \"hyperopt\",\n",
    "    \"model_type\": \"xgboost|10\",\n",
    "    \"xgbg\": \"uniform|0,0.2\",\n",
    "    \"xgbl\": \"loguniform|-2,2\",\n",
    "\n",
    "    \"result_dir\": f\"./{best_model_dir},./{model_dir}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In **Tutorial 6, \"Compare Models to Select the Best Hyperparameters\"**, we analyze the performance of these large sets of models to select the best hyperparameters for production models.\n",
    "\n",
    "If you have specific feedback about a tutorial, please complete the **[AMPL Tutorial Evaluation](https://forms.gle/pa9sHj4MHbS5zG7A6)**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atomsci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
